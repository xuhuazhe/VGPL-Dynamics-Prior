{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "reward_seqs = [0.0, 0.18974148, 0.1992907, 0.350656, 0.35882896, 0.39109656, \\\n",
    " 0.39486712, 0.39511558, 0.46375644, 0.47071177, 0.5655106, 0.70239437, \\\n",
    " 0.70598173, 0.72608304, 0.7819717, 0.79253316, 0.8283197, 0.9700098, \\\n",
    " 0.99150366, 1.0] \n",
    "fig, axs = plt.subplots(1, 3)\n",
    "fig.set_size_inches(24, 4.8)\n",
    "for i in range(3):\n",
    "    ax = axs[i]\n",
    "    ax.scatter(np.random.randint(5, size=20), \n",
    "        np.random.randint(5, size=20),\n",
    "        c=reward_seqs, cmap=cm.jet)\n",
    "    # ax.scatter(init_pose_seqs[idx[-best_k:], i, self.gripper_mid_pt, 0], \n",
    "    #     init_pose_seqs[idx[-best_k:], i, self.gripper_mid_pt, 2], marker='v', \n",
    "    #     c=reward_seqs[idx[-best_k:]])\n",
    "    # ax.scatter(init_pose_seqs[idx[:-best_k], i, self.gripper_mid_pt, 0], \n",
    "    #     init_pose_seqs[idx[:-best_k], i, self.gripper_mid_pt, 2], \n",
    "    #     c=reward_seqs[idx[:-best_k]])\n",
    "    # ax.scatter(selected[:, i, 0], selected[:, i, 2], c='r')\n",
    "    # ax.scatter(others[:, i, 0], others[:, i, 2], color=[0.0,0.3,0.7,0.3])\n",
    "\n",
    "    ax.set_title(f\"GRIP {i+1}\")\n",
    "    ax.set_xlabel('x coordinate')\n",
    "    ax.set_ylabel('z coordinate')\n",
    "\n",
    "color_map = cm.ScalarMappable(cmap=cm.jet)\n",
    "color_map.set_array(reward_seqs)\n",
    "plt.colorbar(color_map, ax=axs)\n",
    "\n",
    "# plt.savefig(path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix adaptation evolution strategy (CMA-ES)\n",
    "def optimize_action_CMA_ES(   \n",
    "    self,\n",
    "    init_pose_seqs,\n",
    "    act_seqs,\n",
    "    reward_seqs,    # [n_sample]\n",
    "    best_k_ratio=0.05\n",
    "):\n",
    "    best_k = max(3, int(init_pose_seqs.shape[0] * best_k_ratio))\n",
    "    m = np.mean(init_pose_seqs)\n",
    "    n_samples = init_pose_seqs.shape[0]\n",
    "    C = np.eye(n_samples)\n",
    "    p_sigma = 0\n",
    "    p_c = 0\n",
    "    idx = np.argsort(reward_seqs)\n",
    "    print(f\"Selected top reward seqs: {reward_seqs[idx[-best_k:]]}\")\n",
    "    # print(f\"Selected top init pose seqs: {init_pose_seqs[idx[-best_k:], :, self.gripper_mid_pt, :7]}\")\n",
    "\n",
    "    self.visualize_sampled_init_pos(init_pose_seqs, reward_seqs, idx, \\\n",
    "        os.path.join(self.rollout_path, f'plot_cem_s{self.sample_iter_cur}_o{self.opt_iter_cur}'))\n",
    "\n",
    "    init_pose_seqs_sample = []\n",
    "    act_seqs_sample = []\n",
    "    for i in range(best_k, 0, -1):\n",
    "        init_pose_seq = init_pose_seqs[idx[-i]]\n",
    "        # print(f\"Selected init pose seq: {init_pose_seq[:, self.gripper_mid_pt, :7]}\")\n",
    "        init_pose_seqs_sample.append(init_pose_seq)\n",
    "        act_seqs_sample.append(act_seqs[idx[-i]])\n",
    "        j = 1\n",
    "\n",
    "        if i > 1:\n",
    "            n_samples = int(init_pose_seqs.shape[0] / (2**i))\n",
    "        else:\n",
    "            n_samples = init_pose_seqs.shape[0] - len(init_pose_seqs_sample) + 1\n",
    "        \n",
    "        while j < n_samples:\n",
    "            mid_point_seq, angle_seq = self.get_center_and_rot_from_pose(init_pose_seq)\n",
    "            init_pose_seq_sample = []\n",
    "            for k in range(init_pose_seq.shape[0]):\n",
    "                p_noise = np.clip(np.array([0, 0, np.random.randn()*0.03]), a_max=0.1, a_min=-0.1)\n",
    "                rot_noise = np.clip(np.random.randn() * np.pi / 36, a_max=0.1, a_min=-0.1)\n",
    "            \n",
    "                new_mid_point = mid_point_seq[k, :3] + p_noise\n",
    "                new_angle = angle_seq[k] + rot_noise\n",
    "                init_pose = self.get_pose(new_mid_point, new_angle)\n",
    "                init_pose_seq_sample.append(init_pose)\n",
    "\n",
    "                # import pdb; pdb.set_trace()\n",
    "\n",
    "            init_pose_seq_sample = np.stack(init_pose_seq_sample)\n",
    "            act_seq_sample = self.get_action_seq_from_pose(init_pose_seq_sample)\n",
    "\n",
    "            init_pose_seqs_sample.append(init_pose_seq_sample)\n",
    "            act_seqs_sample.append(act_seq_sample)\n",
    "            \n",
    "            # print(f\"Selected init pose seq: {init_pose_seq_sample[:, self.gripper_mid_pt, :7]}\")\n",
    "\n",
    "            j += 1\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    init_pose_seqs_sample = np.stack(init_pose_seqs_sample)\n",
    "    act_seqs_sample = np.stack(act_seqs_sample)\n",
    "\n",
    "    return init_pose_seqs_sample, act_seqs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def optimize_action_MPPI(   # Model-Predictive Path Integral (MPPI)\n",
    "        self,\n",
    "        init_pose_seqs,\n",
    "        act_seqs,       # [n_sample, -1, action_dim]\n",
    "        reward_seqs     # [n_sample]\n",
    "    ):\n",
    "        print(f\"reward_seqs: {reward_seqs}\")\n",
    "        # [n_sample, 1, 1]\n",
    "        # reward_seqs_exp = np.exp(self.reward_weight * (reward_seqs - np.mean(reward_seqs)))\n",
    "        reward_seqs = (reward_seqs - np.mean(reward_seqs)) / np.var(reward_seqs)\n",
    "        reward_seqs_norm = reward_seqs / np.linalg.norm(reward_seqs)\n",
    "        reward_seqs_exp = np.exp(self.reward_weight * reward_seqs_norm)\n",
    "        print(f\"reward_seqs_exp: {reward_seqs_exp}\")\n",
    "\n",
    "        # [-1, action_dim]\n",
    "        eps = 1e-8\n",
    "        mid_point_x = np.full((self.n_sample, init_pose_seqs.shape[1]), self.mid_point[0])\n",
    "        \n",
    "        rot_noise_seqs = np.arccos((init_pose_seqs[:, :, self.gripper_mid_pt, 0] - mid_point_x) / self.sample_radius)\n",
    "        print(rot_noise_seqs)\n",
    "        print(reward_seqs_exp.reshape(-1, 1))\n",
    "        print(reward_seqs_exp.reshape(-1, 1) * rot_noise_seqs)\n",
    "\n",
    "        rot_noise_seq = np.sum(reward_seqs_exp.reshape(-1, 1) * rot_noise_seqs, axis=0) / (np.sum(reward_seqs_exp) + eps)\n",
    "        # act_seq = np.sum(reward_seqs_exp.reshape(-1, 1, 1, 1) * act_seqs, axis=0) / (np.sum(reward_seqs_exp) + eps)\n",
    "\n",
    "        print(f\"rot_noise_seq: {rot_noise_seq}\")\n",
    "\n",
    "        init_pose_seq = []\n",
    "        act_seq = []\n",
    "        for rot_noise in rot_noise_seq:\n",
    "            init_pose_seq.append(self.get_pose(self.mid_point, rot_noise))\n",
    "            act_seq.append(self.get_action_seq(rot_noise))\n",
    "\n",
    "        init_pose_seq = np.stack(init_pose_seq)\n",
    "        act_seq = np.stack(act_seq)\n",
    "        \n",
    "        # [-1, action_dim]\n",
    "        return init_pose_seq, act_seq"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
